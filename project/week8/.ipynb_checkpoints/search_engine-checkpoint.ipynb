{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691a8a3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'jhe-koen-dev.en'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Do Indexing\u001b[39;00m\n\u001b[0;32m     33\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjhe-koen-dev.en\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Specify the file name\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m file_tokens_pairs \u001b[38;5;241m=\u001b[39m indexing(file_name) \u001b[38;5;66;03m# Index the file and get the list of token sets\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Input the query\u001b[39;00m\n\u001b[0;32m     37\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m영어 쿼리를 입력하세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Ask the user to enter a query\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m, in \u001b[0;36mindexing\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexing\u001b[39m(file_name):\n\u001b[0;32m     10\u001b[0m     file_tokens_pairs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# Initialize a list to store the tokens of each line\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreadlines() \u001b[38;5;66;03m# Read the sentences from the file and save them in a variable\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines: \u001b[38;5;66;03m# For each line in the file\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m preprocess(line) \u001b[38;5;66;03m# Preprocess the line and get the set of tokens\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'jhe-koen-dev.en'"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "# Preprocess function: This function takes a sentence as input, converts it to lowercase, tokenizes it into words, and returns a set of tokens.\n",
    "def preprocess(sentence):\n",
    "    preprocessed_sentence = set(sentence.strip().lower().split(\" \"))\n",
    "    return preprocessed_sentence\n",
    "\n",
    "# Indexing function: This function reads lines from a given file, preprocesses each line, and returns a list of sets of tokens.\n",
    "def indexing(file_name):\n",
    "    file_tokens_pairs = [] # Initialize a list to store the tokens of each line\n",
    "    lines = open(file_name, \"r\", encoding=\"utf8\").readlines() # Read the sentences from the file and save them in a variable\n",
    "   \n",
    "    for line in lines: # For each line in the file\n",
    "        tokens = preprocess(line) # Preprocess the line and get the set of tokens\n",
    "        file_tokens_pairs.append(tokens) # Add the set of tokens to the list\n",
    "    return file_tokens_pairs # Return the list of token sets\n",
    "\n",
    "# Calculate similarity function: This function calculates the similarity score between the query and each sentence in the file.\n",
    "def calc_similarity(preprocessed_query, preprocessed_sentences):\n",
    "    score_dict = {} # Initialize a dictionary to store the similarity scores\n",
    "    query_token_set = set(preprocessed_query) # Convert the query into a set of tokens\n",
    "   \n",
    "    # For each sentence in the file, calculate the Jaccard similarity and store it in the dictionary\n",
    "    for i, sentence_tokens in enumerate(preprocessed_sentences):\n",
    "        all_tokens = query_token_set | sentence_tokens\n",
    "        same_tokens = query_token_set & sentence_tokens\n",
    "        similarity = len(same_tokens) / len(all_tokens) # Calculate the Jaccard similarity\n",
    "        score_dict[i] = similarity # Store the similarity score in the dictionary\n",
    "\n",
    "    return score_dict # Return the dictionary of similarity scores\n",
    "\n",
    "# Do Indexing\n",
    "file_name = \"jhe-koen-dev.en\" # Specify the file name\n",
    "file_tokens_pairs = indexing(file_name) # Index the file and get the list of token sets\n",
    "\n",
    "# Input the query\n",
    "query = input(\"영어 쿼리를 입력하세요.\") # Ask the user to enter a query\n",
    "preprocessed_query = preprocess(query) # Preprocess the query\n",
    "\n",
    "# Calculate similarities based on the same token set\n",
    "score_dict = calc_similarity(preprocessed_query, file_tokens_pairs) # Calculate the similarity scores\n",
    "\n",
    "# Sort the similarity list\n",
    "sorted_score_list = sorted(score_dict.items(), key=operator.itemgetter(1), reverse=True) # Sort the similarity scores in descending order\n",
    "\n",
    "# Print the result\n",
    "if sorted_score_list[0][1] == 0.0: # If the highest similarity score is 0\n",
    "    print(\"There is no similar sentence.\") # Print a message indicating that there is no similar sentence\n",
    "else:\n",
    "    print(\"rank\", \"Index\", \"score\", \"sentence\", sep=\"\\t\") # Print the headers of the result\n",
    "    print(\"Input sentence : \", query) # Print the input query\n",
    "    rank = 1 # Initialize the rank\n",
    "    for i, score in sorted_score_list[:10]: # For each of the top 10 similarity scores\n",
    "        print(rank, i, score, ' '.join(file_tokens_pairs[i]), sep=\"\\t\") # Print the rank, index, score, and sentence\n",
    "        rank += 1 # Increase the rank by 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd981d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
